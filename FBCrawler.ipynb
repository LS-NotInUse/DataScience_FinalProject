{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "class FbCrawler:\n",
    "    def __init__(self, page_name, since=None, until=None):\n",
    "        self.access_token = \"&access_token=\" + \"EAACEdEose0cBAKvu3lU1PGeOPnSsxeZAwBpaYQsbNDineZB4ZCtfaYVaxTPG9dZAWxlEXxVx6g45cpFspoWwSctqQfr98fAEJu5szTb6yoDAosUJWPb5Jz7rDqLx6BdaPeJl8LnFWPSst4SBOsXBJf9eS4FuGyGbVvHRnIlGsBylO2KbHAXBbGXzIk7ECwB4Us2sgQwyRAZDZD\"\n",
    "        self.page_url = (\"https://graph.facebook.com/v3.0/%s/posts?\" %page_name)\n",
    "        self.since, self.until = since, until\n",
    "        try:\n",
    "            self.file_name = \"post_\"+self.since+\"_\"+self.until+\".txt\"\n",
    "        except:\n",
    "            self.file_name = \"post_all.txt\"\n",
    "        self.all_posts = list()\n",
    "    \n",
    "    def clearPosts(self):\n",
    "        self.all_posts = list()\n",
    "        \n",
    "    def getPosts(self, next_posts=None):\n",
    "        time_range = \"%s%s\" %(\"\"if self.since is None else \"&since=\"+self.since, \"\"if self.until is None else \"&until=\"+self.until)\n",
    "        final_url = (self.page_url+ self.access_token + time_range) if next_posts is None else next_posts\n",
    "#         print(final_url)\n",
    "        \n",
    "        posts_json = json.loads(requests.get(final_url).text)\n",
    "        for data in posts_json[\"data\"]:\n",
    "            self.all_posts.append(data)\n",
    "            \n",
    "        if ((next_posts is not None) or ((self.since is not None) and (self.until is not None))):\n",
    "            try:\n",
    "                self.getPosts(posts_json[\"paging\"][\"next\"])\n",
    "            except:\n",
    "                print(\"get post done\")\n",
    "        \n",
    "            \n",
    "    def printPosts(self):\n",
    "        if(len(self.all_posts) == 0):\n",
    "            print(\"empty\")\n",
    "            return\n",
    "        print(\"count: \" + str(len(self.all_posts)))\n",
    "        for element in self.all_posts:\n",
    "            print(element[\"created_time\"])\n",
    "    \n",
    "    def writePosts(self):\n",
    "        with open(self.file_name, \"w\") as writer:\n",
    "            writer.write(json.dumps(self.all_posts))\n",
    "        print(\"write done\")\n",
    "    \n",
    "    def readPosts(self):\n",
    "        with open(self.file_name, \"r\") as reader:\n",
    "            self.all_posts = json.load(reader)\n",
    "        print(\"read done\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_name = \"DoctorKoWJ\"\n",
    "posts_since = \"2017-1-1\"\n",
    "posts_until = \"2017-5-1\"\n",
    "\n",
    "# crawler = FbCrawler(page_name)\n",
    "# crawler.getPosts()\n",
    "# crawler.printPosts()\n",
    "# crawler.writePosts()\n",
    "\n",
    "# crawler.clearPosts()\n",
    "\n",
    "crawler = FbCrawler(page_name, posts_since, posts_until)\n",
    "crawler.getPosts()\n",
    "# crawler.printPosts()\n",
    "crawler.writePosts()\n",
    "crawler.readPosts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
